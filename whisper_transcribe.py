#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
üéôÔ∏è –ú–∞—Å—Å–æ–≤–æ–µ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ –∞—É–¥–∏–æ —Å –ø–æ–º–æ—â—å—é OpenAI Whisper üéôÔ∏è

–≠—Ç–æ—Ç Python-—Å–∫—Ä–∏–ø—Ç –ø—Ä–µ–¥–Ω–∞–∑–Ω–∞—á–µ–Ω –¥–ª—è –ø–∞–∫–µ—Ç–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∞—É–¥–∏–æ—Ñ–∞–π–ª–æ–≤ (mp3, wav, m4a)
–≤ —É–∫–∞–∑–∞–Ω–Ω–æ–π –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏, –∏—Å–ø–æ–ª—å–∑—É—è –º–æ–¥–µ–ª—å OpenAI Whisper –¥–ª—è —Ç—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏–∏ —Ä–µ—á–∏.
–°–∫—Ä–∏–ø—Ç –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω –¥–ª—è —Ä–∞–±–æ—Ç—ã –Ω–∞ GPU NVIDIA –¥–ª—è –∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω–æ–≥–æ —É—Å–∫–æ—Ä–µ–Ω–∏—è.

–ù–∞–ø–æ–º–∏–Ω–∞–Ω–∏–µ: –î–ª—è –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–π –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ —É–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ —É –≤–∞—Å —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω—ã
—Å–æ–≤–º–µ—Å—Ç–∏–º—ã–µ –¥—Ä–∞–π–≤–µ—Ä—ã NVIDIA, CUDA –∏ PyTorch —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π CUDA.

–û—Å–Ω–æ–≤–Ω—ã–µ –∑–∞–¥–∞—á–∏:
- –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ GPU, –µ—Å–ª–∏ –æ–Ω –¥–æ—Å—Ç—É–ø–µ–Ω.
- –ü–æ–∏—Å–∫ –≤—Å–µ—Ö –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã—Ö –∞—É–¥–∏–æ—Ñ–∞–π–ª–æ–≤ –≤ –∑–∞–¥–∞–Ω–Ω–æ–π –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏.
- –ü–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –∫–∞–∂–¥–æ–≥–æ —Ñ–∞–π–ª–∞ —Å –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ–º –ø—Ä–æ–≥—Ä–µ—Å—Å–∞.
- –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –≤ –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö —Ñ–æ—Ä–º–∞—Ç–∞—Ö –¥–ª—è —É–¥–æ–±—Å—Ç–≤–∞:
  - .txt: —á–∏—Å—Ç—ã–π —Ç–µ–∫—Å—Ç –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —Ñ–∞–π–ª–∞.
  - .srt: —Ñ–∞–π–ª —Å—É–±—Ç–∏—Ç—Ä–æ–≤ —Å –≤—Ä–µ–º–µ–Ω–Ω—ã–º–∏ –º–µ—Ç–∫–∞–º–∏.
  - all_transcripts.txt: –æ–±—â–∏–π —Ñ–∞–π–ª —Å–æ –≤—Å–µ–º–∏ —Ç–µ–∫—Å—Ç–∞–º–∏.
- –í—ã–≤–æ–¥ –∏—Ç–æ–≥–æ–≤–æ–π —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –ø–æ –æ–∫–æ–Ω—á–∞–Ω–∏–∏ —Ä–∞–±–æ—Ç—ã.

–ü–æ—Ä—è–¥–æ–∫ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è:
1. –ê–∫—Ç–∏–≤–∏—Ä—É–π—Ç–µ –≤–∏—Ä—Ç—É–∞–ª—å–Ω–æ–µ –æ–∫—Ä—É–∂–µ–Ω–∏–µ: source .venv/bin/activate
2. –ó–∞–ø—É—Å—Ç–∏—Ç–µ —Å–∫—Ä–∏–ø—Ç, —É–∫–∞–∑–∞–≤ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –≤ –∫–æ–º–∞–Ω–¥–Ω–æ–π —Å—Ç—Ä–æ–∫–µ:
   python whisper_transcribe.py <–ø—É—Ç—å_–∫_–∞—É–¥–∏–æ> <–º–æ–¥–µ–ª—å> <–ø–∞–ø–∫–∞_—Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤>
3. –ï—Å–ª–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –Ω–µ —É–∫–∞–∑–∞–Ω—ã, –±—É–¥—É—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω—ã –∑–Ω–∞—á–µ–Ω–∏—è –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é.

–ê–≤—Ç–æ—Ä: –ú–∏—Ö–∞–∏–ª –®–∞—Ä–¥–∏–Ω https://shardin.name/
–î–∞—Ç–∞ —Å–æ–∑–¥–∞–Ω–∏—è: 29.08.2025
–í–µ—Ä—Å–∏—è: 1.0

–ê–∫—Ç—É–∞–ª—å–Ω–∞—è –≤–µ—Ä—Å–∏—è —Å–∫—Ä–∏–ø—Ç–∞ –≤—Å–µ–≥–¥–∞ –∑–¥–µ—Å—å: https://github.com/empenoso/offline-audio-transcriber

"""

import os
import sys
import glob
import json
import time
from pathlib import Path
import whisper
import torch

def check_gpu():
    """–ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç–∏ CUDA –∏ GPU —Å —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ–º —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏"""
    if not torch.cuda.is_available():
        print("‚ùå CUDA –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞. –ë—É–¥–µ—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å—Å—è CPU")
        return False
    
    try:
        gpu_name = torch.cuda.get_device_name(0)
        memory_gb = torch.cuda.get_device_properties(0).total_memory / 1024**3
        print(f"üéÆ –ù–∞–π–¥–µ–Ω GPU: {gpu_name}")
        print(f"üíæ –ü–∞–º—è—Ç—å GPU: {memory_gb:.1f} GB")
        
        # –¢–µ—Å—Ç —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏ GPU - —Å–æ–∑–¥–∞–µ–º –Ω–µ–±–æ–ª—å—à–æ–π —Ç–µ–Ω–∑–æ—Ä
        test_tensor = torch.zeros(10, 10).cuda()
        _ = test_tensor + 1  # –ü—Ä–æ—Å—Ç–∞—è –æ–ø–µ—Ä–∞—Ü–∏—è
        test_tensor = test_tensor.cpu()  # –û—Å–≤–æ–±–æ–∂–¥–∞–µ–º –ø–∞–º—è—Ç—å
        del test_tensor
        torch.cuda.empty_cache()
        
        print("‚úÖ GPU —Å–æ–≤–º–µ—Å—Ç–∏–º —Å PyTorch")
        return True
        
    except Exception as e:
        print(f"‚ö†Ô∏è  GPU –Ω–∞–π–¥–µ–Ω, –Ω–æ –Ω–µ—Å–æ–≤–º–µ—Å—Ç–∏–º —Å —Ç–µ–∫—É—â–∏–º PyTorch: {str(e)}")
        print("üîÑ –ü–µ—Ä–µ–∫–ª—é—á–µ–Ω–∏–µ –Ω–∞ CPU —Ä–µ–∂–∏–º")
        return False

def load_whisper_model(model_size="medium", use_gpu=True):
    """–ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ Whisper —Å –æ–±—Ä–∞–±–æ—Ç–∫–æ–π –æ—à–∏–±–æ–∫ GPU"""
    print(f"üîÑ –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ Whisper ({model_size})...")
    
    device = "cuda" if use_gpu and torch.cuda.is_available() else "cpu"
    
    try:
        model = whisper.load_model(model_size, device=device)
        print(f"‚úÖ –ú–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞ –Ω–∞ {device}")
        return model, device
    except Exception as e:
        if device == "cuda":
            print(f"‚ö†Ô∏è  –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –Ω–∞ GPU: {str(e)}")
            print("üîÑ –ü–µ—Ä–µ–∫–ª—é—á–µ–Ω–∏–µ –Ω–∞ CPU...")
            model = whisper.load_model(model_size, device="cpu")
            print(f"‚úÖ –ú–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞ –Ω–∞ CPU")
            return model, "cpu"
        else:
            raise e

def get_audio_files(directory):
    """–ü–æ–∏—Å–∫ –∞—É–¥–∏–æ—Ñ–∞–π–ª–æ–≤ –≤ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏"""
    audio_extensions = ['*.wav', '*.mp3', '*.m4a', '*.WAV', '*.MP3', '*.M4A']
    files = []
    
    for ext in audio_extensions:
        files.extend(glob.glob(os.path.join(directory, ext)))
    
    return sorted(files)

def transcribe_audio(model, file_path, device="cpu", language="ru"):
    """–†–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ –æ–¥–Ω–æ–≥–æ –∞—É–¥–∏–æ—Ñ–∞–π–ª–∞"""
    print(f"üéµ –û–±—Ä–∞–±–∞—Ç—ã–≤–∞—é: {os.path.basename(file_path)}")
    
    try:
        # –ó–∞—Å–µ–∫–∞–µ–º –≤—Ä–µ–º—è –æ–±—Ä–∞–±–æ—Ç–∫–∏
        start_time = time.time()
        
        # –†–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ —Å —É–∫–∞–∑–∞–Ω–∏–µ–º —è–∑—ã–∫–∞
        result = model.transcribe(
            file_path, 
            language=language,
            verbose=False,
            fp16=device == "cuda"  # –ò—Å–ø–æ–ª—å–∑—É–µ–º fp16 —Ç–æ–ª—å–∫–æ –¥–ª—è GPU
        )
        
        processing_time = time.time() - start_time
        
        # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ç–µ–∫—Å—Ç –∏ —Å–µ–≥–º–µ–Ω—Ç—ã
        text = result["text"].strip()
        segments = result.get("segments", [])
        
        print(f"‚úÖ –ì–æ—Ç–æ–≤–æ –∑–∞ {processing_time:.1f}—Å")
        
        return {
            "file": file_path,
            "text": text,
            "segments": segments,
            "language": result.get("language", language),
            "processing_time": processing_time
        }
        
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ {file_path}: {e}")
        return None

def save_single_result(result, output_dir):
    """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ –æ–¥–Ω–æ–≥–æ —Ñ–∞–π–ª–∞ —Å—Ä–∞–∑—É –ø–æ—Å–ª–µ –æ–±—Ä–∞–±–æ—Ç–∫–∏"""
    if not result:
        return
        
    os.makedirs(output_dir, exist_ok=True)
    
    base_name = os.path.splitext(os.path.basename(result['file']))[0]
    
    # –¢–µ–∫—Å—Ç–æ–≤—ã–π —Ñ–∞–π–ª
    individual_txt = os.path.join(output_dir, f"{base_name}.txt")
    with open(individual_txt, 'w', encoding='utf-8') as f:
        f.write(result['text'])
    
    # SRT —Å—É–±—Ç–∏—Ç—Ä—ã (–µ—Å–ª–∏ –µ—Å—Ç—å —Å–µ–≥–º–µ–Ω—Ç—ã)
    if result['segments']:
        srt_path = os.path.join(output_dir, f"{base_name}.srt")
        with open(srt_path, 'w', encoding='utf-8') as f:
            for i, segment in enumerate(result['segments'], 1):
                start = format_timestamp(segment['start'])
                end = format_timestamp(segment['end'])
                text = segment['text'].strip()
                f.write(f"{i}\n{start} --> {end}\n{text}\n\n")
    
    # –î–æ–±–∞–≤–ª—è–µ–º –≤ –æ–±—â–∏–π —Ñ–∞–π–ª
    all_txt_path = os.path.join(output_dir, "all_transcripts.txt")
    with open(all_txt_path, 'a', encoding='utf-8') as f:
        f.write(f"=== {os.path.basename(result['file'])} ===\n")
        f.write(f"{result['text']}\n\n")
    
    print(f"üíæ –§–∞–π–ª —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {base_name}.txt, {base_name}.srt")

def save_final_json(results, output_dir):
    """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ñ–∏–Ω–∞–ª—å–Ω–æ–≥–æ JSON —Ñ–∞–π–ª–∞ —Å–æ –≤—Å–µ–º–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏"""
    os.makedirs(output_dir, exist_ok=True)
    
    # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ JSON —Å –¥–µ—Ç–∞–ª—å–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π
    json_path = os.path.join(output_dir, "transcripts_detailed.json")
    with open(json_path, 'w', encoding='utf-8') as f:
        json.dump(results, f, ensure_ascii=False, indent=2)

def format_timestamp(seconds):
    """–§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –≤—Ä–µ–º–µ–Ω–∏ –¥–ª—è SRT"""
    hours = int(seconds // 3600)
    minutes = int((seconds % 3600) // 60)
    secs = int(seconds % 60)
    millis = int((seconds % 1) * 1000)
    return f"{hours:02d}:{minutes:02d}:{secs:02d},{millis:03d}"

def print_statistics(results):
    """–í—ã–≤–æ–¥ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –æ–±—Ä–∞–±–æ—Ç–∫–∏"""
    successful = [r for r in results if r is not None]
    failed = len(results) - len(successful)
    
    if successful:
        total_time = sum(r['processing_time'] for r in successful)
        avg_time = total_time / len(successful)
        total_text = sum(len(r['text']) for r in successful)
        
        print(f"\nüìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞:")
        print(f"‚úÖ –£—Å–ø–µ—à–Ω–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {len(successful)} —Ñ–∞–π–ª–æ–≤")
        print(f"‚ùå –û—à–∏–±–æ–∫: {failed}")
        print(f"‚è±Ô∏è  –û–±—â–µ–µ –≤—Ä–µ–º—è: {total_time:.1f}—Å")
        print(f"‚ö° –°—Ä–µ–¥–Ω–µ–µ –≤—Ä–µ–º—è –Ω–∞ —Ñ–∞–π–ª: {avg_time:.1f}—Å")
        print(f"üìù –í—Å–µ–≥–æ —Å–∏–º–≤–æ–ª–æ–≤ —Ä–∞—Å–ø–æ–∑–Ω–∞–Ω–æ: {total_text}")

def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    print("üéôÔ∏è  –°–∫—Ä–∏–ø—Ç —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è —Ä—É—Å—Å–∫–æ–π —Ä–µ—á–∏ —Å OpenAI Whisper\n")
    
    # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã (–º–æ–∂–Ω–æ –∏–∑–º–µ–Ω–∏—Ç—å)
    input_directory = "."  # –¢–µ–∫—É—â–∞—è –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è
    output_directory = "transcripts"
    model_size = "large"  # tiny, base, small, medium, large
    language = "ru"  # –†—É—Å—Å–∫–∏–π —è–∑—ã–∫
    
    # –ü–æ–ª—É—á–µ–Ω–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –∏–∑ –∞—Ä–≥—É–º–µ–Ω—Ç–æ–≤ –∫–æ–º–∞–Ω–¥–Ω–æ–π —Å—Ç—Ä–æ–∫–∏
    if len(sys.argv) > 1:
        input_directory = sys.argv[1]
    if len(sys.argv) > 2:
        model_size = sys.argv[2]
    if len(sys.argv) > 3:
        output_directory = sys.argv[3]
    
    print(f"üìÅ –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è —Å –∞—É–¥–∏–æ: {input_directory}")
    print(f"üéØ –ú–æ–¥–µ–ª—å: {model_size}")
    print(f"üíæ –í—ã—Ö–æ–¥–Ω–∞—è –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è: {output_directory}")
    print(f"üåç –Ø–∑—ã–∫: {language}\n")
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ GPU
    use_gpu = check_gpu()
    print()
    
    # –ü–æ–∏—Å–∫ –∞—É–¥–∏–æ—Ñ–∞–π–ª–æ–≤
    audio_files = get_audio_files(input_directory)
    
    if not audio_files:
        print(f"‚ùå –ê—É–¥–∏–æ—Ñ–∞–π–ª—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã –≤ {input_directory}")
        print("–ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–µ —Ñ–æ—Ä–º–∞—Ç—ã: wav, mp3, m4a")
        return
    
    print(f"üéµ –ù–∞–π–¥–µ–Ω–æ {len(audio_files)} –∞—É–¥–∏–æ—Ñ–∞–π–ª–æ–≤:")
    for file in audio_files:
        size_mb = os.path.getsize(file) / (1024 * 1024)
        print(f"  - {os.path.basename(file)} ({size_mb:.1f} MB)")
    print()
    
    # –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏
    model, actual_device = load_whisper_model(model_size, use_gpu)
    print()
    
    # –°–æ–∑–¥–∞–µ–º –≤—ã—Ö–æ–¥–Ω—É—é –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –∏ –æ—á–∏—â–∞–µ–º –æ–±—â–∏–π —Ñ–∞–π–ª
    os.makedirs(output_directory, exist_ok=True)
    
    # –û—á–∏—â–∞–µ–º –æ–±—â–∏–π —Ñ–∞–π–ª –≤ –Ω–∞—á–∞–ª–µ
    all_txt_path = os.path.join(output_directory, "all_transcripts.txt")
    with open(all_txt_path, 'w', encoding='utf-8') as f:
        f.write("")  # –û—á–∏—â–∞–µ–º —Ñ–∞–π–ª
    
    # –û–±—Ä–∞–±–æ—Ç–∫–∞ —Ñ–∞–π–ª–æ–≤ —Å –Ω–µ–º–µ–¥–ª–µ–Ω–Ω—ã–º —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ–º
    results = []
    total_files = len(audio_files)
    
    print(f"üöÄ –ù–∞—á–∏–Ω–∞—é –æ–±—Ä–∞–±–æ—Ç–∫—É {total_files} —Ñ–∞–π–ª–æ–≤ –Ω–∞ {actual_device.upper()}...\n")
    
    for i, file_path in enumerate(audio_files, 1):
        print(f"[{i}/{total_files}] ", end="")
        result = transcribe_audio(model, file_path, actual_device, language)
        
        if result:
            results.append(result)
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç —Å—Ä–∞–∑—É –ø–æ—Å–ª–µ –æ–±—Ä–∞–±–æ—Ç–∫–∏
            save_single_result(result, output_directory)
            
            # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø—Ä–µ–≤—å—é —Ç–µ–∫—Å—Ç–∞
            if result['text']:
                preview = result['text'][:100] + "..." if len(result['text']) > 100 else result['text']
                print(f"üìù –ü—Ä–µ–≤—å—é: {preview}")
        else:
            results.append(None)
        print()
    
    # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ñ–∏–Ω–∞–ª—å–Ω–æ–≥–æ JSON —Ñ–∞–π–ª–∞
    print("üíæ –°–æ—Ö—Ä–∞–Ω—è—é –∏—Ç–æ–≥–æ–≤—ã–π JSON...")
    save_final_json(results, output_directory)
    
    # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
    print_statistics(results)
    
    print(f"\nüéâ –ì–æ—Ç–æ–≤–æ! –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ {output_directory}/")
    print(f"üìÑ –§–∞–π–ª—ã:")
    print(f"  - all_transcripts.txt (–≤–µ—Å—å —Ç–µ–∫—Å—Ç)")
    print(f"  - transcripts_detailed.json (JSON —Å –¥–µ—Ç–∞–ª—è–º–∏)")
    print(f"  - [–∏–º—è_—Ñ–∞–π–ª–∞].txt (–æ—Ç–¥–µ–ª—å–Ω—ã–µ —Ç–µ–∫—Å—Ç–æ–≤—ã–µ —Ñ–∞–π–ª—ã)")
    print(f"  - [–∏–º—è_—Ñ–∞–π–ª–∞].srt (—Å—É–±—Ç–∏—Ç—Ä—ã)")

if __name__ == "__main__":
    # –°–ø—Ä–∞–≤–∫–∞ –ø–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—é
    if len(sys.argv) > 1 and sys.argv[1] in ['-h', '--help']:
        print("–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ:")
        print("  python whisper_transcribe.py [–¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è] [–º–æ–¥–µ–ª—å] [–≤—ã—Ö–æ–¥–Ω–∞—è_–ø–∞–ø–∫–∞]")
        print("\n–ü—Ä–∏–º–µ—Ä—ã:")
        print("  python whisper_transcribe.py")
        print("  python whisper_transcribe.py ./audio")
        print("  python whisper_transcribe.py ./audio large ./results")
        print("\n–ú–æ–¥–µ–ª–∏: tiny, base, small, medium, large")
        print("–ß–µ–º –±–æ–ª—å—à–µ –º–æ–¥–µ–ª—å, —Ç–µ–º —Ç–æ—á–Ω–µ–µ, –Ω–æ –º–µ–¥–ª–µ–Ω–Ω–µ–µ")
        sys.exit(0)
    
    try:
        main()
    except KeyboardInterrupt:
        print("\n\n‚ùå –ü—Ä–µ—Ä–≤–∞–Ω–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º")
    except Exception as e:
        print(f"\n‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞: {e}")
        sys.exit(1)